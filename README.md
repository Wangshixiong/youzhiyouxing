# 有知有行 "E大干货合集" 本地备份脚本

这是一个 Python 爬虫脚本，用于从“有知有行”网站 (`youzhiyouxing.cn`) 爬取 "E大干货合集" 的所有文章，并将其保存为一个完整的、可离线阅读的本地 Markdown 知识库。

## 核心功能

* **完整备份：** 自动爬取「投资理念」、「投资策略」、「人生哲学」三个板块的全部文章。
* **结构保留：** 智能地将网页内容“翻译”为 Markdown 格式，完美保留原始的文章结构，包括：
    * 小标题 (H2)
    * 段落 (p)
    * *斜体/强调* (em)
    * **加粗** (strong)
    * 无序/有序列表 (ul/ol)
* **图片本地化：** 自动下载所有文章中的图片（包括懒加载的 `data-src` 图片），并保存到统一的 `images` 文件夹中。
* **路径重写：** 自动将 `.md` 文件中的图片链接重写为本地相对路径 (`../../images/...`)，确保离线阅读时图片正常显示。
* **原文链接：** 保留每篇文章末尾的“原文发表于...”超链接，并将其格式化为 Markdown 引用。
* **自动生成目录：** 脚本会自动在根目录创建 `README.md` 文件，作为整个知识库的总目录。
* **数据备份：** 同时生成 `youzhiyouxing_articles.json` 文件，包含所有文章的元数据。

## 运行环境

* Python 3.x
* 第三方库: `requests`, `beautifulsoup4`, `lxml`

## 如何使用

1.  **安装依赖库:**
    在运行脚本之前，请确保已安装所有必需的 Python 库：
    ```bash
    pip install requests beautifulsoup4 lxml
    ```

2.  **保存脚本:**
    将您收到的 `v7.1` 版本脚本保存为一个 `.py` 文件（例如：`scrape_yzyx.py`）。

3.  **运行脚本:**
    打开您的终端或命令行，切换到脚本所在的目录，然后运行：
    ```bash
    python scrape_yzyx.py
    ```

4.  **完成:**
    脚本会开始爬取，您会看到实时的日志输出。完成后，**在脚本所在的同一目录**下，会生成一个名为 `E大干货合集` 的完整文件夹。

## 最终输出目录结构

脚本运行完毕后，您将得到如下所示的文件结构：

```
./scrape\_yzyx.py  \<-- (您运行的脚本)
./E大干货合集/
├── README.md                (自动生成的总目录)
├── youzhiyouxing\_articles.json (JSON 备份)
├── images/                    (所有文章的图片)
│   ├── [hash1].jpg
│   └── [hash2].png
├── 01-投资理念/
│   ├── 开篇介绍/
│   │   └── 导-跟车前，先了解E大.md
│   └── 第一章 投资是科学，也是艺术/
│       └── 01-投资是一场赌博.md
├── 02-投资策略/
│   └── ...
└── 03-人生哲学/
└── ...
```

## 注意事项

* 脚本已设置 `time.sleep(1)`，以““有礼貌””的方式爬取，不会对服务器造成过大压力。
* 图片使用 MD5 哈希值重命名，可自动跳过已下载的图片，支持““断点续传””。
* 本脚本仅供个人学习和备份知识使用。
